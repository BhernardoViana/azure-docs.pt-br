---
title: Referência da API de registro em log do Azure ML | Microsoft Docs
description: Referência da API de registro em log.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ROBOTS: NOINDEX
ms.openlocfilehash: 7084251102984445e7c2341b78b44f85811ebea7
ms.sourcegitcommit: 32d218f5bd74f1cd106f4248115985df631d0a8c
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 09/24/2018
ms.locfileid: "46958213"
---
# <a name="logging-api-reference"></a>Referência da API de registro em log

[!INCLUDE [workbench-deprecated](../../../includes/aml-deprecating-preview-2017.md)] 

A biblioteca de registro em log do Azure ML permite que o programa emita métricas e arquivos controlados pelo serviço de histórico para serem analisados posteriormente. 

## <a name="uploading-metrics"></a>Carregamento de métricas

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

Por padrão, todas as métricas são enviadas de forma assíncrona para que o envio não impessa a execução do programa. Isso pode causar problemas de ordenação quando várias métricas são enviadas em casos extremos. Um exemplo disso seria duas métricas registradas ao mesmo tempo, mas que por algum motivo o usuário prefere preservar a ordenação exata. Outro caso é quando a métrica deve ser controlada antes da execução de algum código conhecido por potencialmente falhar rapidamente. Em ambos os casos, a solução é _esperar_ até que a métrica seja totalmente registrada antes de continuar:

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>Consumo de métricas

As métricas são armazenadas pelo serviço de histórico e vinculadas à execução que as produziu. A guia Histórico de execução e o comando da CLI abaixo permitem recuperá-las (e os artefatos abaixo) após a conclusão de uma execução.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>Artefatos (arquivos)

Além das métricas, o AzureML também permite que o usuário controle arquivos. Por padrão, todos os arquivos gravados na pasta `outputs` relativa ao diretório de trabalho do programa (a pasta de projeto no contexto da computação) são carregados no serviço de histórico e controlados para analisar posteriormente. A limitação é que o tamanho de cada arquivo deve ser menor que 512 MB.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>Consumo de artefatos

Para imprimir o conteúdo de um artefato que foi controlado, o usuário pode usar a guia Histórico de execução de uma dada execução para **Baixar** ou **Promover** o Artefato ou usar os comandos da CLI abaixo para obter o mesmo efeito.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>Próximas etapas
- Explore o [tutorial Classificar íris, parte 2](tutorial-classifying-iris-part-2.md) para ver a API de registro em log em ação.
- Reveja [Como usar o histórico de execuções e as métricas de modelo no Azure Machine Learning Workbench](how-to-use-run-history-model-metrics.md) para entender melhor como as APIs de registro em log podem ser usadas no histórico de execuções.
